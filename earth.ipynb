{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cda138d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target distribution:\n",
      " damage_class\n",
      "high      459609\n",
      "medium    223670\n",
      "low        78815\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.83      0.69      0.75     91922\n",
      "         low       0.43      0.74      0.54     15763\n",
      "      medium       0.43      0.47      0.45     44734\n",
      "\n",
      "    accuracy                           0.63    152419\n",
      "   macro avg       0.56      0.63      0.58    152419\n",
      "weighted avg       0.67      0.63      0.64    152419\n",
      "\n",
      "\n",
      "Model saved to models/RandomForest.pkl\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import joblib\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# # ===============================\n",
    "\n",
    "# # 1. Load merged dataset\n",
    "\n",
    "# # ===============================\n",
    "\n",
    "# df = pd.read_csv(\"Data/Nepal_building_with_Intensity.csv\")\n",
    "\n",
    "# # Check target column\n",
    "\n",
    "# if \"damage_grade\" not in df.columns:\n",
    "#     raise Exception(\"Dataset must contain 'damage_grade' column.\")\n",
    "\n",
    "# # Convert 0–5 → 0–10\n",
    "\n",
    "# df[\"damage_score\"] = (df[\"damage_grade\"] / df[\"damage_grade\"].max()) * 10\n",
    "\n",
    "# # Categorize into low/medium/high\n",
    "\n",
    "# df[\"damage_class\"] = pd.cut(\n",
    "# df[\"damage_score\"],\n",
    "# bins=[-0.1, 3.3, 6.6, 10],\n",
    "# labels=[\"low\", \"medium\", \"high\"]\n",
    "# )\n",
    "\n",
    "\n",
    "# print(\"Target distribution:\\n\", df[\"damage_class\"].value_counts())\n",
    "\n",
    "# # ===============================\n",
    "\n",
    "# # 2. Define features\n",
    "\n",
    "# # ===============================\n",
    "\n",
    "# numeric_features = [\"count_floors_pre_eq\", \"age_building\", \"plinth_area_sq_ft\", \"intensity\"]\n",
    "# categorical_features = [\"foundation_type\", \"roof_type\"]\n",
    "\n",
    "# X = df[numeric_features + categorical_features]\n",
    "# y = df[\"damage_class\"]\n",
    "\n",
    "# # ===============================\n",
    "\n",
    "# # 3. Preprocessing pipeline with NaN handling\n",
    "\n",
    "# # ===============================\n",
    "\n",
    "# numeric_transformer = Pipeline([\n",
    "# (\"imputer\", SimpleImputer(strategy=\"median\")),  # fill NaNs with median\n",
    "# (\"scaler\", StandardScaler())\n",
    "# ])\n",
    "\n",
    "# categorical_transformer = Pipeline([\n",
    "# (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),  # fill NaNs with mode\n",
    "# (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "# ])\n",
    "\n",
    "# preprocessor = ColumnTransformer(\n",
    "# transformers=[\n",
    "# (\"num\", numeric_transformer, numeric_features),\n",
    "# (\"cat\", categorical_transformer, categorical_features)\n",
    "# ]\n",
    "# )\n",
    "\n",
    "# # ===============================\n",
    "\n",
    "# # 4. Train/test split\n",
    "\n",
    "# # ===============================\n",
    "\n",
    "# #drop the things with nan values\n",
    "\n",
    "\n",
    "# # Drop rows with any NaN in features or target\n",
    "# df = df.dropna(subset=numeric_features + categorical_features + [\"damage_class\"])\n",
    "\n",
    "# X = df[numeric_features + categorical_features]\n",
    "# y = df[\"damage_class\"]\n",
    "\n",
    "# # Now train_test_split will work\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.2, random_state=42, stratify=y\n",
    "# )\n",
    "\n",
    "\n",
    "# # ===============================\n",
    "\n",
    "# # 5. Random Forest model pipeline\n",
    "\n",
    "# # ===============================\n",
    "\n",
    "# rf_pipeline = Pipeline([\n",
    "# (\"preprocessor\", preprocessor),\n",
    "# (\"classifier\", RandomForestClassifier(n_estimators=200, max_depth=12, random_state=42, class_weight=\"balanced\"))\n",
    "# ])\n",
    "\n",
    "# # Train\n",
    "\n",
    "# rf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# # ===============================\n",
    "\n",
    "# # 6. Evaluate\n",
    "\n",
    "# # ===============================\n",
    "\n",
    "# y_pred = rf_pipeline.predict(X_test)\n",
    "# print(\"\\nClassification Report:\\n\")\n",
    "# print(classification_report(y_test, y_pred))\n",
    "\n",
    "# # ===============================\n",
    "\n",
    "# # 7. Save trained model\n",
    "\n",
    "# # ===============================\n",
    "\n",
    "# joblib.dump(rf_pipeline, \"models/RandomForest.pkl\")\n",
    "# print(\"\\nModel saved to models/RandomForest.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2c9ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = joblib.load(\"models/RandomForest.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98490777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples = pd.DataFrame([\n",
    "#     {   # Low damage\n",
    "#         \"count_floors_pre_eq\": 1,\n",
    "#         \"age_building\": 5,\n",
    "#         \"plinth_area_sq_ft\": 50,\n",
    "#         \"intensity\": 2.0,\n",
    "#         \"foundation_type\": \"Mud mortar-Stone/Brick\",\n",
    "#         \"roof_type\": \"Bamboo/Timber-Light roof\"\n",
    "#     },\n",
    "#     {   # Medium damage\n",
    "#         \"count_floors_pre_eq\": 2,\n",
    "#         \"age_building\": 25,\n",
    "#         \"plinth_area_sq_ft\": 120,\n",
    "#         \"intensity\": 4.5,\n",
    "#         \"foundation_type\": \"Mud mortar-Stone/Brick\",\n",
    "#         \"roof_type\": \"Bamboo/Timber-Light roof\"\n",
    "#     },\n",
    "#     {   # High damage\n",
    "#         \"count_floors_pre_eq\": 4,\n",
    "#         \"age_building\": 60,\n",
    "#         \"plinth_area_sq_ft\": 200,\n",
    "#         \"intensity\": 7.5,\n",
    "#         \"foundation_type\": \"Mud mortar-Stone/Brick\",\n",
    "#         \"roof_type\": \"Bamboo/Timber-Light roof\"\n",
    "#     }\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df5f917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted damage class:  ['medium' 'high' 'high']\n",
      "Predict probability:  [[0.22161472 0.31202439 0.46636088]\n",
      " [0.52827983 0.10943107 0.3622891 ]\n",
      " [0.78210758 0.02521668 0.19267574]]\n"
     ]
    }
   ],
   "source": [
    "# predicted_class = model.predict(samples)\n",
    "# print(\"Predicted damage class: \", predicted_class)\n",
    "\n",
    "# predicted_prob = model.predict_proba(samples)\n",
    "# print(\"Predict probability: \", predicted_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa87b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.utils import resample\n",
    "\n",
    "# # Separate classes\n",
    "# df_low = df[df['damage_class'] == 'low']\n",
    "# df_med = df[df['damage_class'] == 'medium']\n",
    "# df_high = df[df['damage_class'] == 'high']\n",
    "\n",
    "# # Upsample low and medium to match high\n",
    "# df_low_upsampled = resample(df_low, replace=True, n_samples=len(df_high), random_state=42)\n",
    "# df_med_upsampled = resample(df_med, replace=True, n_samples=len(df_high), random_state=42)\n",
    "\n",
    "# # Combine\n",
    "# df_balanced = pd.concat([df_low_upsampled, df_med_upsampled, df_high])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8cfbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# rf = RandomForestClassifier(\n",
    "#     n_estimators=200,\n",
    "#     max_depth=12,\n",
    "#     random_state=42,\n",
    "#     class_weight=\"balanced\"\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d309bdda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution:\n",
      " damage_class\n",
      "high      459609\n",
      "medium    223670\n",
      "low        78815\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.93      0.69      0.79     91922\n",
      "         low       0.60      0.76      0.67     15763\n",
      "      medium       0.22      0.47      0.30     15763\n",
      "\n",
      "    accuracy                           0.67    123448\n",
      "   macro avg       0.58      0.64      0.59    123448\n",
      "weighted avg       0.79      0.67      0.71    123448\n",
      "\n",
      "\n",
      "Model saved to models/RandomForest_balanced.pkl\n",
      "\n",
      "Synthetic test data:\n",
      "     count_floors_pre_eq  age_building  plinth_area_sq_ft  intensity  \\\n",
      "0                     4            30                219   7.693313   \n",
      "1                     5            38                219   7.793792   \n",
      "2                     3             2                204   6.850384   \n",
      "3                     5            64                219   3.827683   \n",
      "4                     5            60                 80   2.586033   \n",
      "5                     2            21                137   6.105398   \n",
      "6                     3            33                 84   4.640915   \n",
      "7                     3            76                 93   2.732229   \n",
      "8                     3            58                160   4.971061   \n",
      "9                     5            22                 80   2.206331   \n",
      "10                    4            49                164   7.455922   \n",
      "11                    3            59                 50   3.552680   \n",
      "12                    5            42                102   5.975134   \n",
      "13                    2            60                196   3.870266   \n",
      "14                    4            15                 47   5.120408   \n",
      "\n",
      "           foundation_type                 roof_type  \n",
      "0                      RCC                      Tile  \n",
      "1                    Stone                     Metal  \n",
      "2                      RCC                       RCC  \n",
      "3   Mud mortar-Stone/Brick                      Tile  \n",
      "4           Brick-Concrete                     Metal  \n",
      "5                      RCC  Bamboo/Timber-Light roof  \n",
      "6                      RCC                       RCC  \n",
      "7                    Stone                     Metal  \n",
      "8                      RCC  Bamboo/Timber-Light roof  \n",
      "9                      RCC                     Metal  \n",
      "10                     RCC  Bamboo/Timber-Light roof  \n",
      "11                   Stone                       RCC  \n",
      "12                     RCC                      Tile  \n",
      "13          Brick-Concrete  Bamboo/Timber-Light roof  \n",
      "14                   Stone                     Metal  \n",
      "\n",
      "Predictions:\n",
      " ['high' 'high' 'high' 'high' 'high' 'medium' 'low' 'high' 'high' 'high'\n",
      " 'high' 'high' 'high' 'medium' 'low']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# ===============================\n",
    "\n",
    "# 1. Load dataset\n",
    "\n",
    "# ===============================\n",
    "\n",
    "df = pd.read_csv(\"Data/Nepal_building_with_Intensity.csv\")\n",
    "\n",
    "if \"damage_grade\" not in df.columns:\n",
    "    raise Exception(\"Dataset must contain 'damage_grade' column.\")\n",
    "\n",
    "# Convert 0-5 → 0-10\n",
    "\n",
    "df[\"damage_score\"] = (df[\"damage_grade\"] / df[\"damage_grade\"].max()) * 10\n",
    "\n",
    "# Categorize into low/medium/high\n",
    "\n",
    "df[\"damage_class\"] = pd.cut(\n",
    "df[\"damage_score\"],\n",
    "bins=[-0.1, 3.3, 6.6, 10],\n",
    "labels=[\"low\", \"medium\", \"high\"]\n",
    ")\n",
    "\n",
    "print(\"Original class distribution:\\n\", df[\"damage_class\"].value_counts())\n",
    "\n",
    "# ===============================\n",
    "\n",
    "# 2. Balance classes by upsampling\n",
    "\n",
    "# ===============================\n",
    "\n",
    "df_low = df[df['damage_class'] == 'low']\n",
    "df_med = df[df['damage_class'] == 'medium']\n",
    "df_high = df[df['damage_class'] == 'high']\n",
    "\n",
    "df_low_up = resample(df_low, replace=True, n_samples=len(df_low), random_state=42)\n",
    "df_med_up = resample(df_med, replace=True, n_samples=len(df_low), random_state=42)\n",
    "\n",
    "df_balanced = pd.concat([df_high, df_low_up, df_med_up])\n",
    "# print(df_balanced.shape)\n",
    "# print(\"\\nBalanced class distribution:\\n\", df_balanced[\"damage_class\"].value_counts())\n",
    "# df_balanced.drop_duplicates(inplace=True)\n",
    "\n",
    "# print(df_balanced.shape)\n",
    "# ===============================\n",
    "\n",
    "# 3. Define features\n",
    "\n",
    "# ===============================\n",
    "\n",
    "numeric_features = [\"count_floors_pre_eq\", \"age_building\", \"plinth_area_sq_ft\", \"intensity\"]\n",
    "categorical_features = [\"foundation_type\", \"roof_type\"]\n",
    "\n",
    "X = df_balanced[numeric_features + categorical_features]\n",
    "y = df_balanced[\"damage_class\"]\n",
    "X.shape\n",
    "y.shape\n",
    "# ===============================\n",
    "\n",
    "# 4. Preprocessing pipeline with NaN handling\n",
    "\n",
    "# ===============================\n",
    "\n",
    "numeric_transformer = Pipeline([\n",
    "(\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "(\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "(\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "(\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "(\"num\", numeric_transformer, numeric_features),\n",
    "(\"cat\", categorical_transformer, categorical_features)\n",
    "])\n",
    "\n",
    "# ===============================\n",
    "\n",
    "# 5. Train/test split\n",
    "\n",
    "# ===============================\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "\n",
    "# 6. Random Forest pipeline\n",
    "\n",
    "# ===============================\n",
    "\n",
    "rf_pipeline = Pipeline([\n",
    "(\"preprocessor\", preprocessor),\n",
    "(\"classifier\", RandomForestClassifier(\n",
    "n_estimators=200,\n",
    "max_depth=12,\n",
    "random_state=42,\n",
    "class_weight=\"balanced\"\n",
    "))\n",
    "])\n",
    "\n",
    "# Train\n",
    "\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# ===============================\n",
    "\n",
    "# 7. Evaluate\n",
    "\n",
    "# ===============================\n",
    "\n",
    "y_pred = rf_pipeline.predict(X_test)\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# ===============================\n",
    "\n",
    "# 8. Save model\n",
    "\n",
    "# ===============================\n",
    "\n",
    "joblib.dump(rf_pipeline, \"models/RandomForest_balanced.pkl\")\n",
    "print(\"\\nModel saved to models/RandomForest_balanced.pkl\")\n",
    "\n",
    "# ===============================\n",
    "\n",
    "# 9. Generate synthetic test data\n",
    "\n",
    "# ===============================\n",
    "\n",
    "np.random.seed(42)\n",
    "n_samples = 15\n",
    "\n",
    "test_df = pd.DataFrame({\n",
    "\"count_floors_pre_eq\": np.random.randint(1, 6, n_samples),\n",
    "\"age_building\": np.random.randint(1, 80, n_samples),\n",
    "\"plinth_area_sq_ft\": np.random.randint(30, 250, n_samples),\n",
    "\"intensity\": np.random.uniform(2, 8, n_samples),\n",
    "\"foundation_type\": np.random.choice(\n",
    "[\"Mud mortar-Stone/Brick\",\"RCC\",\"Brick-Concrete\",\"Stone\"], n_samples\n",
    "),\n",
    "\"roof_type\": np.random.choice(\n",
    "[\"Bamboo/Timber-Light roof\",\"RCC\",\"Tile\",\"Metal\"], n_samples\n",
    ")\n",
    "})\n",
    "\n",
    "print(\"\\nSynthetic test data:\\n\", test_df)\n",
    "\n",
    "# ===============================\n",
    "\n",
    "# 10. Predict on synthetic test data\n",
    "\n",
    "# ===============================\n",
    "\n",
    "preds = rf_pipeline.predict(test_df)\n",
    "print(\"\\nPredictions:\\n\", preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080219b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = pd.DataFrame([\n",
    "    {   # High damage\n",
    "        \"count_floors_pre_eq\": 2,\n",
    "        \"age_building\": 20,\n",
    "        \"plinth_area_sq_ft\": 1000,\n",
    "        \"intensity\": 7.5\n",
    "    }\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cc8e8378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions:\n",
      " ['medium' 'high' 'high']\n"
     ]
    }
   ],
   "source": [
    "preds = rf_pipeline.predict(samples)\n",
    "print(\"\\nPredictions:\\n\", preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e2a4b16b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.value_counts of          building_id  district_id  vdcmun_id  ward_id  count_floors_pre_eq  \\\n",
       "0       1.201010e+11           12       1207   120703                    1   \n",
       "1       1.201010e+11           12       1207   120703                    1   \n",
       "2       1.201010e+11           12       1207   120703                    1   \n",
       "3       1.201010e+11           12       1207   120703                    1   \n",
       "4       1.201010e+11           12       1207   120703                    1   \n",
       "...              ...          ...        ...      ...                  ...   \n",
       "762101  3.667090e+11           36       3603   360302                    2   \n",
       "762102  3.667090e+11           36       3603   360302                    2   \n",
       "762103  3.667090e+11           36       3603   360302                    2   \n",
       "762104  3.667090e+11           36       3603   360302                    2   \n",
       "762105  3.667090e+11           36       3603   360302                    2   \n",
       "\n",
       "        count_floors_post_eq  age_building  plinth_area_sq_ft  \\\n",
       "0                          1             9                288   \n",
       "1                          1            15                364   \n",
       "2                          1            20                384   \n",
       "3                          1            20                312   \n",
       "4                          1            30                308   \n",
       "...                      ...           ...                ...   \n",
       "762101                     0            60                165   \n",
       "762102                     0            35                342   \n",
       "762103                     0            35                342   \n",
       "762104                     0            19                306   \n",
       "762105                     0            12                840   \n",
       "\n",
       "        height_ft_pre_eq  height_ft_post_eq  ... other_floor_type  \\\n",
       "0                      9                  9  ...   Not applicable   \n",
       "1                      9                  9  ...   Not applicable   \n",
       "2                      9                  9  ...   Not applicable   \n",
       "3                      9                  9  ...   Not applicable   \n",
       "4                      9                  9  ...   Not applicable   \n",
       "...                  ...                ...  ...              ...   \n",
       "762101                18                  0  ...    Timber-Planck   \n",
       "762102                18                  0  ...    Timber-Planck   \n",
       "762103                18                  0  ...    Timber-Planck   \n",
       "762104                18                  0  ...    Timber-Planck   \n",
       "762105                18                  0  ...    Timber-Planck   \n",
       "\n",
       "               position plan_configuration          condition_post_eq  \\\n",
       "0          Not attached        Rectangular       Damaged-Used in risk   \n",
       "1          Not attached        Rectangular  Damaged-Repaired and used   \n",
       "2          Not attached        Rectangular  Damaged-Repaired and used   \n",
       "3          Not attached        Rectangular  Damaged-Repaired and used   \n",
       "4          Not attached        Rectangular  Damaged-Repaired and used   \n",
       "...                 ...                ...                        ...   \n",
       "762101  Attached-2 side        Rectangular       Damaged-Rubble clear   \n",
       "762102  Attached-1 side        Rectangular       Damaged-Rubble clear   \n",
       "762103     Not attached        Rectangular       Damaged-Rubble clear   \n",
       "762104     Not attached        Rectangular       Damaged-Rubble clear   \n",
       "762105     Not attached        Rectangular       Damaged-Rubble clear   \n",
       "\n",
       "       damage_grade technical_solution_proposed  \\\n",
       "0               3.0                Major repair   \n",
       "1               3.0              Reconstruction   \n",
       "2               2.0                Minor repair   \n",
       "3               2.0                Minor repair   \n",
       "4               1.0                Minor repair   \n",
       "...             ...                         ...   \n",
       "762101          5.0              Reconstruction   \n",
       "762102          5.0              Reconstruction   \n",
       "762103          5.0              Reconstruction   \n",
       "762104          5.0              Reconstruction   \n",
       "762105          5.0              Reconstruction   \n",
       "\n",
       "                             superstructure damage_score  damage_class  \\\n",
       "0       has_superstructure_mud_mortar_stone          6.0        medium   \n",
       "1       has_superstructure_mud_mortar_stone          6.0        medium   \n",
       "2       has_superstructure_mud_mortar_stone          4.0        medium   \n",
       "3       has_superstructure_mud_mortar_stone          4.0        medium   \n",
       "4       has_superstructure_mud_mortar_stone          2.0           low   \n",
       "...                                     ...          ...           ...   \n",
       "762101  has_superstructure_mud_mortar_stone         10.0          high   \n",
       "762102  has_superstructure_mud_mortar_stone         10.0          high   \n",
       "762103  has_superstructure_mud_mortar_stone         10.0          high   \n",
       "762104  has_superstructure_mud_mortar_stone         10.0          high   \n",
       "762105  has_superstructure_mud_mortar_stone         10.0          high   \n",
       "\n",
       "       intensity  \n",
       "0       5.339286  \n",
       "1       5.339286  \n",
       "2       5.339286  \n",
       "3       5.339286  \n",
       "4       5.339286  \n",
       "...          ...  \n",
       "762101  4.111940  \n",
       "762102  4.111940  \n",
       "762103  4.111940  \n",
       "762104  4.111940  \n",
       "762105  4.111940  \n",
       "\n",
       "[762106 rows x 24 columns]>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2732f6fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
